{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6b34dc4e",
      "metadata": {
        "lines_to_next_cell": 0,
        "id": "6b34dc4e"
      },
      "source": [
        "# Outlook\n",
        "\n",
        "This notebook is designed to understand how to use a gymnasium environment as a BBRL agent in practice, using autoreset=False.\n",
        "It is part of the [BBRL documentation](https://github.com/osigaud/bbrl/docs/index.html).\n",
        "\n",
        "If this is your first contact with BBRL, you may start be having a look at [this more basic notebook](01-basic_concepts.student.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ce2d0a6",
      "metadata": {
        "id": "8ce2d0a6"
      },
      "source": [
        "## Installation and Imports\n",
        "\n",
        "The BBRL library is [here](https://github.com/osigaud/bbrl).\n",
        "\n",
        "Below, we import standard python packages, pytorch packages and gymnasium environments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "fe8daeda",
      "metadata": {
        "tags": [
          "hide-input"
        ],
        "id": "fe8daeda"
      },
      "outputs": [],
      "source": [
        "# Installs the necessary Python and system libraries\n",
        "try:\n",
        "    from easypip import easyimport, easyinstall, is_notebook\n",
        "except ModuleNotFoundError as e:\n",
        "    get_ipython().run_line_magic(\"pip\", \"install easypip\")\n",
        "    from easypip import easyimport, easyinstall, is_notebook\n",
        "\n",
        "easyinstall(\"bbrl>=0.2.2\")\n",
        "easyinstall(\"swig\")\n",
        "easyinstall(\"bbrl_gymnasium>=0.2.0\")\n",
        "easyinstall(\"bbrl_gymnasium[classic_control]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "a3c0ede2",
      "metadata": {
        "tags": [
          "hide-input"
        ],
        "id": "a3c0ede2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import math\n",
        "\n",
        "from moviepy.editor import ipython_display as video_display\n",
        "import time\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Tuple, Optional\n",
        "from functools import partial\n",
        "\n",
        "from omegaconf import OmegaConf\n",
        "import torch\n",
        "import bbrl_gymnasium\n",
        "\n",
        "import copy\n",
        "from abc import abstractmethod, ABC\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from time import strftime\n",
        "OmegaConf.register_new_resolver(\n",
        "    \"current_time\", lambda: strftime(\"%Y%m%d-%H%M%S\"), replace=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "646bd8de",
      "metadata": {
        "tags": [
          "hide-input"
        ],
        "id": "646bd8de"
      },
      "outputs": [],
      "source": [
        "# Imports all the necessary classes and functions from BBRL\n",
        "from bbrl.agents.agent import Agent\n",
        "from bbrl import get_arguments, get_class, instantiate_class\n",
        "# The workspace is the main class in BBRL, this is where all data is collected and stored\n",
        "from bbrl.workspace import Workspace\n",
        "\n",
        "# Agents(agent1, agent2, agent3, ...) executes the different agents the one after the other\n",
        "# TemporalAgent(agent) executes an agent over multiple timesteps in the workspace,\n",
        "# or until a given condition is reached\n",
        "\n",
        "from bbrl.agents import Agents, TemporalAgent\n",
        "from bbrl.agents.gymnasium import ParallelGymAgent, make_env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "1949cc01",
      "metadata": {
        "id": "1949cc01"
      },
      "outputs": [],
      "source": [
        "from gymnasium.wrappers.time_limit import TimeLimit"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9e38c6d",
      "metadata": {
        "lines_to_next_cell": 2,
        "id": "f9e38c6d"
      },
      "source": [
        "## Definition of agents\n",
        "\n",
        "We first create an Agent representing [the CartPole-v1 gym environment](https://gymnasium.farama.org/environments/classic_control/cart_pole/).\n",
        "This is done using the [ParallelGymAgent](https://github.com/osigaud/bbrl/blob/40fe0468feb8998e62c3cd6bb3a575fef88e256f/src/bbrl/agents/gymnasium.py#L261) class.\n",
        "\n",
        "The ParallelGymAgent is an agent able to execute a batch of gymnasium environments\n",
        "with or without auto-resetting. These agents produce multiple variables in the workspace:\n",
        "’env/env_obs’, ’env/reward’, ’env/timestep’, ’env/terminated’,\n",
        "'env/truncated', 'env/done', ’env/cumulated_reward’.\n",
        "\n",
        "When called at timestep t=0, the environments are automatically reset. At\n",
        "timestep t>0, these agents will read the ’action’ variable in the workspace at\n",
        "time t − 1 to generate the next state, by calling the step(action) of the contained gymnasium environment.\n",
        "\n",
        "In the example below, we are working with batches (i.e. several episodes at the same time),\n",
        "so here our agent uses `n_envs = 3` environments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "ce253c1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce253c1a",
        "outputId": "65fbc15c-635e-4086-c578-879ac835bcb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment: observation space in R^4 and action space {1, ..., 2}\n"
          ]
        }
      ],
      "source": [
        "# We run episodes over 3 environments at a time\n",
        "n_envs = 3\n",
        "env_agent = ParallelGymAgent(partial(make_env, 'CartPole-v1', autoreset=False, wrappers=[lambda x: TimeLimit(x,100)]), n_envs, reward_at_t=False)\n",
        "# The random seed is set to 2139\n",
        "env_agent.seed(2139)\n",
        "\n",
        "obs_size, action_dim = env_agent.get_obs_and_actions_sizes()\n",
        "print(f\"Environment: observation space in R^{obs_size} and action space {{1, ..., {action_dim}}}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "id": "c28027b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c28027b5",
        "outputId": "39926860-e0fd-425c-ef3d-de0010f08ec3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Observation tensor([[-0.0085, -0.0427, -0.0489,  0.0215],\n",
            "        [ 0.0005,  0.0025, -0.0493, -0.0402],\n",
            "        [ 0.0080,  0.0203, -0.0023, -0.0085]])\n"
          ]
        }
      ],
      "source": [
        "# Creates a new workspace\n",
        "workspace = Workspace()\n",
        "\n",
        "# Execute the first step\n",
        "env_agent(workspace, t=0)\n",
        "\n",
        "# Our first set of observations. The size of the observation space is 4, and we have 3 environments.\n",
        "obs = workspace.get(\"env/env_obs\", 0)\n",
        "print(\"Observation\", obs)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4db311a2",
      "metadata": {
        "id": "4db311a2"
      },
      "source": [
        "To generate more steps into the workspace, we need to send actions to the environment.\n",
        "\n",
        "### Random action without agent\n",
        "\n",
        "We first set an action directly without using an agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "92877535",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92877535",
        "outputId": "dd1d89ab-819a-428d-fc88-f4f9b6f95ba0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 0])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0094,  0.1531, -0.0485, -0.2862],\n",
              "        [ 0.0006,  0.1983, -0.0501, -0.3480],\n",
              "        [ 0.0084, -0.1747, -0.0025,  0.2834]])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "# Sets the next action\n",
        "action = torch.randint(0, action_dim, (n_envs, ))\n",
        "workspace.set(\"action\", 0, action)\n",
        "print(action)\n",
        "env_agent(workspace, t=1)\n",
        "\n",
        "# And perform one step\n",
        "workspace.get(\"env/env_obs\", 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8efe6d64",
      "metadata": {
        "id": "8efe6d64"
      },
      "source": [
        "Let us now look at what's in the workspace. You can see below all the variables it generates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "id": "b8e1e6e7",
      "metadata": {
        "lines_to_next_cell": 1,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8e1e6e7",
        "outputId": "7490f49d-babb-47f0-fe92-69d30e0fc135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env/env_obs tensor([[[-0.0085, -0.0427, -0.0489,  0.0215],\n",
            "         [ 0.0005,  0.0025, -0.0493, -0.0402],\n",
            "         [ 0.0080,  0.0203, -0.0023, -0.0085]],\n",
            "\n",
            "        [[-0.0094,  0.1531, -0.0485, -0.2862],\n",
            "         [ 0.0006,  0.1983, -0.0501, -0.3480],\n",
            "         [ 0.0084, -0.1747, -0.0025,  0.2834]]])\n",
            "env/terminated tensor([[False, False, False],\n",
            "        [False, False, False]])\n",
            "env/truncated tensor([[False, False, False],\n",
            "        [False, False, False]])\n",
            "env/done tensor([[False, False, False],\n",
            "        [False, False, False]])\n",
            "env/reward tensor([[0., 0., 0.],\n",
            "        [1., 1., 1.]])\n",
            "env/cumulated_reward tensor([[0., 0., 0.],\n",
            "        [1., 1., 1.]])\n",
            "env/timestep tensor([[0, 0, 0],\n",
            "        [1, 1, 1]])\n",
            "action tensor([[1, 1, 0]])\n"
          ]
        }
      ],
      "source": [
        "for key in workspace.variables.keys():\n",
        "    print(key, workspace[key])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e810df8",
      "metadata": {
        "id": "5e810df8"
      },
      "source": [
        "You can observe that we have two time steps for each variable that are stored\n",
        "within tensors where the first dimension is time.\n",
        "\n",
        "You can also see that by convention, all variables written by the environment start with \"env/\"."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e305632",
      "metadata": {
        "id": "7e305632"
      },
      "source": [
        "### Random agent\n",
        "\n",
        "The process above can be\n",
        "automatized with `Agents` and `TemporalAgent` as shown below - but first we have\n",
        "to create an agent that selects the actions (here, randomly)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "b7133853",
      "metadata": {
        "id": "b7133853"
      },
      "outputs": [],
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self, action_dim):\n",
        "        super().__init__()\n",
        "        self.action_dim = action_dim\n",
        "\n",
        "    def forward(self, t: int, choose_action=True, **kwargs):\n",
        "        \"\"\"An Agent can use self.workspace\"\"\"\n",
        "        obs = self.get((\"env/env_obs\", t))\n",
        "        action = torch.randint(0, self.action_dim, (len(obs), ))\n",
        "        self.set((\"action\", t), action)\n",
        "\n",
        "# Each agent is run in the order given when constructing Agents\n",
        "agents = Agents(env_agent, RandomAgent(action_dim))\n",
        "\n",
        "# And the TemporalAgent allows to run through time\n",
        "t_agents = TemporalAgent(agents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "eb791f07",
      "metadata": {
        "id": "eb791f07"
      },
      "outputs": [],
      "source": [
        "# We can now run the agents throught time with a simple call...\n",
        "\n",
        "workspace = Workspace()\n",
        "t_agents(workspace, t=0, stop_variable=\"env/done\", stochastic=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "262e3b5d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "262e3b5d",
        "outputId": "a7c7f0e6-3cb8-472e-8df7-760e91cf9b6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env/env_obs tensor([[[ 1.2417e-02, -1.1647e-02,  2.1894e-02,  4.7717e-02],\n",
            "         [ 1.0013e-02, -9.4643e-04, -1.0945e-02, -6.8630e-03],\n",
            "         [ 4.5724e-02,  2.0465e-02,  4.8711e-02,  3.0704e-03]],\n",
            "\n",
            "        [[ 1.2184e-02, -2.0708e-01,  2.2849e-02,  3.4723e-01],\n",
            "         [ 9.9937e-03, -1.9591e-01, -1.1082e-02,  2.8235e-01],\n",
            "         [ 4.6133e-02, -1.7532e-01,  4.8772e-02,  3.1072e-01]],\n",
            "\n",
            "        [[ 8.0423e-03, -4.0252e-01,  2.9793e-02,  6.4703e-01],\n",
            "         [ 6.0755e-03, -6.3148e-04, -5.4349e-03, -1.3811e-02],\n",
            "         [ 4.2627e-02,  1.9074e-02,  5.4987e-02,  3.3804e-02]],\n",
            "\n",
            "        [[-7.9994e-06, -5.9804e-01,  4.2734e-02,  9.4894e-01],\n",
            "         [ 6.0629e-03,  1.9457e-01, -5.7111e-03, -3.0820e-01],\n",
            "         [ 4.3009e-02,  2.1337e-01,  5.5663e-02, -2.4104e-01]],\n",
            "\n",
            "        [[-1.1969e-02, -7.9371e-01,  6.1712e-02,  1.2547e+00],\n",
            "         [ 9.9543e-03,  3.8977e-01, -1.1875e-02, -6.0268e-01],\n",
            "         [ 4.7276e-02,  1.7495e-02,  5.0842e-02,  6.8673e-02]],\n",
            "\n",
            "        [[-2.7843e-02, -9.8957e-01,  8.6807e-02,  1.5661e+00],\n",
            "         [ 1.7750e-02,  5.8506e-01, -2.3929e-02, -8.9908e-01],\n",
            "         [ 4.7626e-02, -1.7832e-01,  5.2216e-02,  3.7695e-01]],\n",
            "\n",
            "        [[-4.7634e-02, -1.1856e+00,  1.1813e-01,  1.8845e+00],\n",
            "         [ 2.9451e-02,  3.9027e-01, -4.1910e-02, -6.1402e-01],\n",
            "         [ 4.4059e-02,  1.6025e-02,  5.9755e-02,  1.0118e-01]],\n",
            "\n",
            "        [[-7.1347e-02, -1.3818e+00,  1.5582e-01,  2.2114e+00],\n",
            "         [ 3.7256e-02,  1.9576e-01, -5.4191e-02, -3.3482e-01],\n",
            "         [ 4.4380e-02, -1.7990e-01,  6.1778e-02,  4.1210e-01]],\n",
            "\n",
            "        [[-9.8983e-02, -1.1885e+00,  2.0005e-01,  1.9706e+00],\n",
            "         [ 4.1171e-02,  3.9160e-01, -6.0887e-02, -6.4409e-01],\n",
            "         [ 4.0782e-02,  1.4294e-02,  7.0020e-02,  1.3952e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 4.9003e-02,  5.8752e-01, -7.3769e-02, -9.5531e-01],\n",
            "         [ 4.1068e-02, -1.8176e-01,  7.2811e-02,  4.5344e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 6.0754e-02,  3.9346e-01, -9.2875e-02, -6.8668e-01],\n",
            "         [ 3.7433e-02,  1.2264e-02,  8.1879e-02,  1.8457e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 6.8623e-02,  5.8974e-01, -1.0661e-01, -1.0071e+00],\n",
            "         [ 3.7678e-02,  2.0612e-01,  8.5571e-02, -8.1202e-02]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 8.0418e-02,  3.9619e-01, -1.2675e-01, -7.4971e-01],\n",
            "         [ 4.1800e-02,  9.8870e-03,  8.3947e-02,  2.3720e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 8.8342e-02,  2.0303e-01, -1.4174e-01, -4.9945e-01],\n",
            "         [ 4.1998e-02, -1.8633e-01,  8.8691e-02,  5.5514e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 9.2402e-02,  3.9983e-01, -1.5173e-01, -8.3323e-01],\n",
            "         [ 3.8272e-02, -3.8258e-01,  9.9794e-02,  8.7440e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.0040e-01,  5.9667e-01, -1.6840e-01, -1.1695e+00],\n",
            "         [ 3.0620e-02, -1.8894e-01,  1.1728e-01,  6.1468e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.1233e-01,  4.0409e-01, -1.9179e-01, -9.3402e-01],\n",
            "         [ 2.6841e-02,  4.3631e-03,  1.2958e-01,  3.6112e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 2.6929e-02,  1.9743e-01,  1.3680e-01,  1.1194e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 3.0877e-02,  3.9035e-01,  1.3904e-01, -1.3465e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 3.8684e-02,  5.8324e-01,  1.3634e-01, -3.8044e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 5.0349e-02,  3.8647e-01,  1.2873e-01, -4.8067e-02]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 5.8078e-02,  5.7953e-01,  1.2777e-01, -2.9752e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 6.9669e-02,  7.7262e-01,  1.2182e-01, -5.4733e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 8.5121e-02,  9.6584e-01,  1.1088e-01, -7.9929e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 1.0444e-01,  7.6939e-01,  9.4890e-02, -4.7389e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 1.1983e-01,  9.6305e-01,  8.5413e-02, -7.3522e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 1.3909e-01,  7.6686e-01,  7.0708e-02, -4.1692e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 1.5442e-01,  5.7081e-01,  6.2370e-02, -1.0281e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 1.6584e-01,  7.6499e-01,  6.0314e-02, -3.7518e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 1.8114e-01,  9.5920e-01,  5.2810e-02, -6.4826e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 2.0032e-01,  7.6338e-01,  3.9845e-02, -3.3942e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 2.1559e-01,  5.6772e-01,  3.3056e-02, -3.4445e-02]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 2.2695e-01,  7.6235e-01,  3.2368e-02, -3.1652e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 2.4219e-01,  9.5700e-01,  2.6037e-02, -5.9882e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 2.6133e-01,  7.6152e-01,  1.4061e-02, -2.9805e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 2.7656e-01,  9.5644e-01,  8.0998e-03, -5.8627e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 2.9569e-01,  7.6121e-01, -3.6255e-03, -2.9104e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 3.1092e-01,  5.6614e-01, -9.4464e-03,  4.9471e-04]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 3.2224e-01,  7.6139e-01, -9.4365e-03, -2.9515e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 3.3747e-01,  9.5665e-01, -1.5340e-02, -5.9080e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 3.5660e-01,  7.6174e-01, -2.7155e-02, -3.0299e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 3.7183e-01,  9.5724e-01, -3.3215e-02, -6.0411e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 3.9098e-01,  1.1528e+00, -4.5297e-02, -9.0707e-01]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 4.1404e-01,  1.3485e+00, -6.3439e-02, -1.2136e+00]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 4.4101e-01,  1.5444e+00, -8.7711e-02, -1.5255e+00]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 4.7189e-01,  1.7405e+00, -1.1822e-01, -1.8442e+00]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 5.0670e-01,  1.5468e+00, -1.5511e-01, -1.5905e+00]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 5.3764e-01,  1.3538e+00, -1.8692e-01, -1.3499e+00]],\n",
            "\n",
            "        [[-1.2275e-01, -1.3851e+00,  2.3946e-01,  2.3180e+00],\n",
            "         [ 1.2041e-01,  6.0121e-01, -2.1047e-01, -1.2803e+00],\n",
            "         [ 5.6472e-01,  1.5508e+00, -2.1391e-01, -1.6948e+00]]])\n",
            "env/terminated tensor([[False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True,  True]])\n",
            "env/truncated tensor([[False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False]])\n",
            "env/done tensor([[False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [False, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True, False, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True, False],\n",
            "        [ True,  True,  True]])\n",
            "env/reward tensor([[0., 0., 0.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 1., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.],\n",
            "        [0., 0., 1.]])\n",
            "env/cumulated_reward tensor([[ 0.,  0.,  0.],\n",
            "        [ 1.,  1.,  1.],\n",
            "        [ 2.,  2.,  2.],\n",
            "        [ 3.,  3.,  3.],\n",
            "        [ 4.,  4.,  4.],\n",
            "        [ 5.,  5.,  5.],\n",
            "        [ 6.,  6.,  6.],\n",
            "        [ 7.,  7.,  7.],\n",
            "        [ 8.,  8.,  8.],\n",
            "        [ 9.,  9.,  9.],\n",
            "        [ 9., 10., 10.],\n",
            "        [ 9., 11., 11.],\n",
            "        [ 9., 12., 12.],\n",
            "        [ 9., 13., 13.],\n",
            "        [ 9., 14., 14.],\n",
            "        [ 9., 15., 15.],\n",
            "        [ 9., 16., 16.],\n",
            "        [ 9., 17., 17.],\n",
            "        [ 9., 17., 18.],\n",
            "        [ 9., 17., 19.],\n",
            "        [ 9., 17., 20.],\n",
            "        [ 9., 17., 21.],\n",
            "        [ 9., 17., 22.],\n",
            "        [ 9., 17., 23.],\n",
            "        [ 9., 17., 24.],\n",
            "        [ 9., 17., 25.],\n",
            "        [ 9., 17., 26.],\n",
            "        [ 9., 17., 27.],\n",
            "        [ 9., 17., 28.],\n",
            "        [ 9., 17., 29.],\n",
            "        [ 9., 17., 30.],\n",
            "        [ 9., 17., 31.],\n",
            "        [ 9., 17., 32.],\n",
            "        [ 9., 17., 33.],\n",
            "        [ 9., 17., 34.],\n",
            "        [ 9., 17., 35.],\n",
            "        [ 9., 17., 36.],\n",
            "        [ 9., 17., 37.],\n",
            "        [ 9., 17., 38.],\n",
            "        [ 9., 17., 39.],\n",
            "        [ 9., 17., 40.],\n",
            "        [ 9., 17., 41.],\n",
            "        [ 9., 17., 42.],\n",
            "        [ 9., 17., 43.],\n",
            "        [ 9., 17., 44.],\n",
            "        [ 9., 17., 45.],\n",
            "        [ 9., 17., 46.],\n",
            "        [ 9., 17., 47.],\n",
            "        [ 9., 17., 48.]])\n",
            "env/timestep tensor([[ 0,  0,  0],\n",
            "        [ 1,  1,  1],\n",
            "        [ 2,  2,  2],\n",
            "        [ 3,  3,  3],\n",
            "        [ 4,  4,  4],\n",
            "        [ 5,  5,  5],\n",
            "        [ 6,  6,  6],\n",
            "        [ 7,  7,  7],\n",
            "        [ 8,  8,  8],\n",
            "        [ 9,  9,  9],\n",
            "        [ 9, 10, 10],\n",
            "        [ 9, 11, 11],\n",
            "        [ 9, 12, 12],\n",
            "        [ 9, 13, 13],\n",
            "        [ 9, 14, 14],\n",
            "        [ 9, 15, 15],\n",
            "        [ 9, 16, 16],\n",
            "        [ 9, 17, 17],\n",
            "        [ 9, 17, 18],\n",
            "        [ 9, 17, 19],\n",
            "        [ 9, 17, 20],\n",
            "        [ 9, 17, 21],\n",
            "        [ 9, 17, 22],\n",
            "        [ 9, 17, 23],\n",
            "        [ 9, 17, 24],\n",
            "        [ 9, 17, 25],\n",
            "        [ 9, 17, 26],\n",
            "        [ 9, 17, 27],\n",
            "        [ 9, 17, 28],\n",
            "        [ 9, 17, 29],\n",
            "        [ 9, 17, 30],\n",
            "        [ 9, 17, 31],\n",
            "        [ 9, 17, 32],\n",
            "        [ 9, 17, 33],\n",
            "        [ 9, 17, 34],\n",
            "        [ 9, 17, 35],\n",
            "        [ 9, 17, 36],\n",
            "        [ 9, 17, 37],\n",
            "        [ 9, 17, 38],\n",
            "        [ 9, 17, 39],\n",
            "        [ 9, 17, 40],\n",
            "        [ 9, 17, 41],\n",
            "        [ 9, 17, 42],\n",
            "        [ 9, 17, 43],\n",
            "        [ 9, 17, 44],\n",
            "        [ 9, 17, 45],\n",
            "        [ 9, 17, 46],\n",
            "        [ 9, 17, 47],\n",
            "        [ 9, 17, 48]])\n",
            "action tensor([[0, 0, 0],\n",
            "        [0, 1, 1],\n",
            "        [0, 1, 1],\n",
            "        [0, 1, 0],\n",
            "        [0, 1, 0],\n",
            "        [0, 0, 1],\n",
            "        [0, 0, 0],\n",
            "        [1, 1, 1],\n",
            "        [0, 1, 0],\n",
            "        [1, 0, 1],\n",
            "        [0, 1, 1],\n",
            "        [0, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 1, 0],\n",
            "        [1, 1, 1],\n",
            "        [1, 0, 1],\n",
            "        [0, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [0, 1, 0],\n",
            "        [0, 0, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 1],\n",
            "        [1, 1, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 0],\n",
            "        [0, 0, 0],\n",
            "        [1, 1, 1],\n",
            "        [0, 1, 1],\n",
            "        [0, 0, 0],\n",
            "        [1, 0, 1],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [1, 0, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 1],\n",
            "        [0, 1, 1],\n",
            "        [1, 0, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 0],\n",
            "        [0, 1, 0],\n",
            "        [1, 1, 1],\n",
            "        [1, 1, 0]])\n"
          ]
        }
      ],
      "source": [
        "for key in workspace.variables.keys():\n",
        "    print(key, workspace[key])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57f2d21e",
      "metadata": {
        "id": "57f2d21e"
      },
      "source": [
        "### Termination\n",
        "\n",
        "`env/done` tells us whether the episode was finished or not (it is either terminated or truncated)\n",
        "here, with NoAutoReset, we wait that all episodes are \"done\"\n",
        "and when the episode is finished, the variables are copied for that environment until all episodes are done.\n",
        "So, when an environment is done before the others, its content is copied until the termination of all environments.\n",
        "This is convenient for collecting the final reward."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "0a3bdf1f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a3bdf1f",
        "outputId": "0fa28923-ec5e-41e7-8428-58bf5600bf05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([49, 3]),\n",
              " tensor([[ True,  True, False],\n",
              "         [ True,  True, False],\n",
              "         [ True,  True, False],\n",
              "         [ True,  True, False],\n",
              "         [ True,  True, False],\n",
              "         [ True,  True, False],\n",
              "         [ True,  True, False],\n",
              "         [ True,  True, False],\n",
              "         [ True,  True, False],\n",
              "         [ True,  True,  True]]))"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "workspace[\"env/done\"].shape, workspace[\"env/done\"][-10:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c4a4ff4",
      "metadata": {
        "id": "6c4a4ff4"
      },
      "source": [
        "You can see that the variable is copied until all episodes are done."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "800669ec",
      "metadata": {
        "id": "800669ec"
      },
      "source": [
        "### Observations\n",
        "\n",
        "The resulting tensor of observations, with the last two observations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "66cc8624",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66cc8624",
        "outputId": "585c543a-53ff-46a2-bc5f-130a316e9999"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([49, 3, 4]),\n",
              " tensor([[[-0.1228, -1.3851,  0.2395,  2.3180],\n",
              "          [ 0.1204,  0.6012, -0.2105, -1.2803],\n",
              "          [ 0.5376,  1.3538, -0.1869, -1.3499]],\n",
              " \n",
              "         [[-0.1228, -1.3851,  0.2395,  2.3180],\n",
              "          [ 0.1204,  0.6012, -0.2105, -1.2803],\n",
              "          [ 0.5647,  1.5508, -0.2139, -1.6948]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "workspace[\"env/env_obs\"].shape, workspace[\"env/env_obs\"][-2:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d2b6c6d",
      "metadata": {
        "id": "5d2b6c6d"
      },
      "source": [
        "### Rewards\n",
        "\n",
        "The resulting tensor of rewards, with the last 8 rewards:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "c046115f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c046115f",
        "outputId": "e87d81dd-8dcf-4091-c3ca-2675bc04fe83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([49, 3]),\n",
              " tensor([[0., 0., 1.],\n",
              "         [0., 0., 1.],\n",
              "         [0., 0., 1.],\n",
              "         [0., 0., 1.],\n",
              "         [0., 0., 1.],\n",
              "         [0., 0., 1.],\n",
              "         [0., 0., 1.],\n",
              "         [0., 0., 1.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "workspace[\"env/reward\"].shape, workspace[\"env/reward\"][-8:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93f417da",
      "metadata": {
        "id": "93f417da"
      },
      "source": [
        "and the cumulated rewards:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "e12520b5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e12520b5",
        "outputId": "4180acd4-ec77-44ce-f657-5a0ef8f37db2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([49, 3]),\n",
              " tensor([[ 9., 17., 41.],\n",
              "         [ 9., 17., 42.],\n",
              "         [ 9., 17., 43.],\n",
              "         [ 9., 17., 44.],\n",
              "         [ 9., 17., 45.],\n",
              "         [ 9., 17., 46.],\n",
              "         [ 9., 17., 47.],\n",
              "         [ 9., 17., 48.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "workspace[\"env/cumulated_reward\"].shape, workspace[\"env/cumulated_reward\"][-8:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "316c63b3",
      "metadata": {
        "id": "316c63b3"
      },
      "source": [
        "### Actions\n",
        "\n",
        "The resulting tensor of actions, with the last two actions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "aad76f54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aad76f54",
        "outputId": "28c204e9-ef2d-4dca-b7b9-472bf68f85da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([49, 3]),\n",
              " tensor([[1, 1, 1],\n",
              "         [1, 1, 0]]))"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ],
      "source": [
        "workspace[\"action\"].shape, workspace[\"action\"][-2:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5456d39",
      "metadata": {
        "id": "e5456d39"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Create a stupid agent that always outputs action 1, until the episode stops.\n",
        "Watch the content of the resulting workspace."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_envs = 5\n",
        "env_agent = ParallelGymAgent(partial(make_env, 'CartPole-v1', autoreset=False), n_envs, reward_at_t=False)\n",
        "env_agent.seed(2139)\n",
        "\n",
        "obs_size, action_dim = env_agent.get_obs_and_actions_sizes()\n",
        "print(f\"Environment: observation space in R^{obs_size} and action space {{1, ..., {action_dim}}}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32cdny377cZw",
        "outputId": "cd245249-fd4f-4dfd-a7f3-79f90a56060d"
      },
      "id": "32cdny377cZw",
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment: observation space in R^4 and action space {1, ..., 2}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OneAgent(Agent):\n",
        "    def __init__(self, action_dim):\n",
        "        super().__init__()\n",
        "        self.action_dim = action_dim\n",
        "\n",
        "    def forward(self, t: int, choose_action=True, **kwargs):\n",
        "        \"\"\"An Agent can use self.workspace\"\"\"\n",
        "        obs = self.get((\"env/env_obs\", t))\n",
        "        action = torch.tensor([1]*len(obs))\n",
        "        self.set((\"action\", t), action)\n",
        "\n",
        "\n",
        "t_agents = TemporalAgent(Agents(env_agent, OneAgent(action_dim)))\n",
        "\n",
        "workspace = Workspace()\n",
        "t_agents(workspace, t=0, stop_variable=\"env/done\", stochastic=True)"
      ],
      "metadata": {
        "id": "qQV73lmz2laV"
      },
      "id": "qQV73lmz2laV",
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in workspace.variables.keys():\n",
        "    print(key, workspace[key])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJXItqbA22uW",
        "outputId": "b8be5e18-2520-4d77-a69e-7e4a355e7334"
      },
      "id": "bJXItqbA22uW",
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env/env_obs tensor([[[ 1.5349e-02, -1.6139e-02, -1.4235e-02,  2.6596e-02],\n",
            "         [-2.9842e-02,  4.2431e-02,  7.2186e-04,  8.1762e-03],\n",
            "         [-8.3105e-03,  6.8620e-03,  1.7204e-02, -1.3014e-02],\n",
            "         [ 1.1758e-02, -4.3135e-02,  1.6623e-02, -9.7311e-03],\n",
            "         [-2.3125e-02,  1.0865e-02,  3.3525e-02, -1.0814e-02]],\n",
            "\n",
            "        [[ 1.5026e-02,  1.7918e-01, -1.3703e-02, -2.7054e-01],\n",
            "         [-2.8993e-02,  2.3754e-01,  8.8538e-04, -2.8428e-01],\n",
            "         [-8.1733e-03,  2.0173e-01,  1.6943e-02, -3.0022e-01],\n",
            "         [ 1.0896e-02,  1.5174e-01,  1.6429e-02, -2.9712e-01],\n",
            "         [-2.2908e-02,  2.0549e-01,  3.3308e-02, -2.9273e-01]],\n",
            "\n",
            "        [[ 1.8610e-02,  3.7450e-01, -1.9114e-02, -5.6752e-01],\n",
            "         [-2.4242e-02,  4.3265e-01, -4.8002e-03, -5.7668e-01],\n",
            "         [-4.1386e-03,  3.9661e-01,  1.0939e-02, -5.8751e-01],\n",
            "         [ 1.3930e-02,  3.4663e-01,  1.0486e-02, -5.8458e-01],\n",
            "         [-1.8798e-02,  4.0012e-01,  2.7454e-02, -5.7473e-01]],\n",
            "\n",
            "        [[ 2.6100e-02,  5.6988e-01, -3.0465e-02, -8.6616e-01],\n",
            "         [-1.5589e-02,  6.2784e-01, -1.6334e-02, -8.7087e-01],\n",
            "         [ 3.7936e-03,  5.9158e-01, -8.1133e-04, -8.7673e-01],\n",
            "         [ 2.0863e-02,  5.4160e-01, -1.2054e-03, -8.7394e-01],\n",
            "         [-1.0795e-02,  5.9485e-01,  1.5959e-02, -8.5864e-01]],\n",
            "\n",
            "        [[ 3.7497e-02,  7.6541e-01, -4.7788e-02, -1.1683e+00],\n",
            "         [-3.0326e-03,  8.2318e-01, -3.3751e-02, -1.1686e+00],\n",
            "         [ 1.5625e-02,  7.8671e-01, -1.8346e-02, -1.1697e+00],\n",
            "         [ 3.1695e-02,  7.3674e-01, -1.8684e-02, -1.1670e+00],\n",
            "         [ 1.1016e-03,  7.8975e-01, -1.2137e-03, -1.1463e+00]],\n",
            "\n",
            "        [[ 5.2806e-02,  9.6112e-01, -7.1153e-02, -1.4755e+00],\n",
            "         [ 1.3431e-02,  1.0187e+00, -5.7124e-02, -1.4717e+00],\n",
            "         [ 3.1359e-02,  9.8207e-01, -4.1739e-02, -1.4680e+00],\n",
            "         [ 4.6430e-02,  9.3210e-01, -4.2024e-02, -1.4655e+00],\n",
            "         [ 1.6897e-02,  9.8489e-01, -2.4139e-02, -1.4393e+00]],\n",
            "\n",
            "        [[ 7.2028e-02,  1.1570e+00, -1.0066e-01, -1.7896e+00],\n",
            "         [ 3.3806e-02,  1.2145e+00, -8.6559e-02, -1.7817e+00],\n",
            "         [ 5.1001e-02,  1.1777e+00, -7.1100e-02, -1.7735e+00],\n",
            "         [ 6.5072e-02,  1.1277e+00, -7.1334e-02, -1.7710e+00],\n",
            "         [ 3.6594e-02,  1.1803e+00, -5.2925e-02, -1.7395e+00]],\n",
            "\n",
            "        [[ 9.5168e-02,  1.3531e+00, -1.3646e-01, -2.1118e+00],\n",
            "         [ 5.8095e-02,  1.4105e+00, -1.2219e-01, -2.1000e+00],\n",
            "         [ 7.4554e-02,  1.3735e+00, -1.0657e-01, -2.0874e+00],\n",
            "         [ 8.7626e-02,  1.3236e+00, -1.0675e-01, -2.0850e+00],\n",
            "         [ 6.0200e-02,  1.3760e+00, -8.7714e-02, -2.0481e+00]],\n",
            "\n",
            "        [[ 1.2223e-01,  1.5493e+00, -1.7869e-01, -2.4433e+00],\n",
            "         [ 8.6305e-02,  1.6066e+00, -1.6419e-01, -2.4278e+00],\n",
            "         [ 1.0202e-01,  1.5695e+00, -1.4832e-01, -2.4110e+00],\n",
            "         [ 1.1410e-01,  1.5196e+00, -1.4845e-01, -2.4087e+00],\n",
            "         [ 8.7720e-02,  1.5719e+00, -1.2868e-01, -2.3666e+00]],\n",
            "\n",
            "        [[ 1.5322e-01,  1.7455e+00, -2.2756e-01, -2.7851e+00],\n",
            "         [ 1.1844e-01,  1.8027e+00, -2.1275e-01, -2.7661e+00],\n",
            "         [ 1.3342e-01,  1.7656e+00, -1.9654e-01, -2.7453e+00],\n",
            "         [ 1.4449e-01,  1.7157e+00, -1.9663e-01, -2.7430e+00],\n",
            "         [ 1.1916e-01,  1.7679e+00, -1.7601e-01, -2.6959e+00]],\n",
            "\n",
            "        [[ 1.5322e-01,  1.7455e+00, -2.2756e-01, -2.7851e+00],\n",
            "         [ 1.1844e-01,  1.8027e+00, -2.1275e-01, -2.7661e+00],\n",
            "         [ 1.6873e-01,  1.9615e+00, -2.5144e-01, -3.0909e+00],\n",
            "         [ 1.7880e-01,  1.9115e+00, -2.5149e-01, -3.0886e+00],\n",
            "         [ 1.5452e-01,  1.9638e+00, -2.2993e-01, -3.0367e+00]]])\n",
            "env/terminated tensor([[False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [ True,  True, False, False, False],\n",
            "        [ True,  True,  True,  True,  True]])\n",
            "env/truncated tensor([[False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False]])\n",
            "env/done tensor([[False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [False, False, False, False, False],\n",
            "        [ True,  True, False, False, False],\n",
            "        [ True,  True,  True,  True,  True]])\n",
            "env/reward tensor([[0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1., 1.],\n",
            "        [0., 0., 1., 1., 1.]])\n",
            "env/cumulated_reward tensor([[ 0.,  0.,  0.,  0.,  0.],\n",
            "        [ 1.,  1.,  1.,  1.,  1.],\n",
            "        [ 2.,  2.,  2.,  2.,  2.],\n",
            "        [ 3.,  3.,  3.,  3.,  3.],\n",
            "        [ 4.,  4.,  4.,  4.,  4.],\n",
            "        [ 5.,  5.,  5.,  5.,  5.],\n",
            "        [ 6.,  6.,  6.,  6.,  6.],\n",
            "        [ 7.,  7.,  7.,  7.,  7.],\n",
            "        [ 8.,  8.,  8.,  8.,  8.],\n",
            "        [ 9.,  9.,  9.,  9.,  9.],\n",
            "        [ 9.,  9., 10., 10., 10.]])\n",
            "env/timestep tensor([[ 0,  0,  0,  0,  0],\n",
            "        [ 1,  1,  1,  1,  1],\n",
            "        [ 2,  2,  2,  2,  2],\n",
            "        [ 3,  3,  3,  3,  3],\n",
            "        [ 4,  4,  4,  4,  4],\n",
            "        [ 5,  5,  5,  5,  5],\n",
            "        [ 6,  6,  6,  6,  6],\n",
            "        [ 7,  7,  7,  7,  7],\n",
            "        [ 8,  8,  8,  8,  8],\n",
            "        [ 9,  9,  9,  9,  9],\n",
            "        [ 9,  9, 10, 10, 10]])\n",
            "action tensor([[1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ils tombent assez rapidement (logique), done = truncated(arreté par la fin de l'épisode) U terminated(fini)"
      ],
      "metadata": {
        "id": "GuIvlAeb7-VI"
      },
      "id": "GuIvlAeb7-VI"
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_markers": "\"\"\""
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}